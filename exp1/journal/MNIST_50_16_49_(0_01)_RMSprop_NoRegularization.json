[
  "epoch 1 saved! Because of Loss",
  "epoch 1 saved! Because of TrainAcc",
  "epoch 1 saved! Because of TestAcc",
  "epoch:1 -> loss:0.024592990055680275 , train_acc:0.86395,test_acc:0.8297",
  "epoch 2 saved! Because of Loss",
  "epoch 2 saved! Because of TrainAcc",
  "epoch:2 -> loss:0.024429192766547203 , train_acc:0.8647,test_acc:0.8218",
  "epoch:3 -> loss:0.024761084467172623 , train_acc:0.8642,test_acc:0.8143",
  "epoch 4 saved! Because of Loss",
  "epoch:4 -> loss:0.02440614439547062 , train_acc:0.86465,test_acc:0.8214",
  "epoch 5 saved! Because of TestAcc",
  "epoch:5 -> loss:0.02474357932806015 , train_acc:0.86335,test_acc:0.8336",
  "epoch:6 -> loss:0.025187592953443527 , train_acc:0.8639833333333333,test_acc:0.8174",
  "epoch:7 -> loss:0.025166688486933708 , train_acc:0.8631833333333333,test_acc:0.8119",
  "epoch 8 saved! Because of TestAcc",
  "epoch:8 -> loss:0.024822548031806946 , train_acc:0.86265,test_acc:0.8362",
  "epoch:9 -> loss:0.02505343034863472 , train_acc:0.8635166666666667,test_acc:0.8278",
  "epoch 10 saved! Because of TestAcc",
  "epoch:10 -> loss:0.025128865614533424 , train_acc:0.8628833333333333,test_acc:0.8382",
  "epoch:11 -> loss:0.025584354996681213 , train_acc:0.8633833333333333,test_acc:0.8164",
  "epoch:12 -> loss:0.02548656426370144 , train_acc:0.8630666666666666,test_acc:0.8329",
  "epoch:13 -> loss:0.025252964347600937 , train_acc:0.8633166666666666,test_acc:0.8363",
  "epoch:14 -> loss:0.025303354486823082 , train_acc:0.8636333333333334,test_acc:0.8277",
  "epoch:15 -> loss:0.02543618343770504 , train_acc:0.8643,test_acc:0.8268",
  "epoch:16 -> loss:0.025965455919504166 , train_acc:0.8631833333333333,test_acc:0.8281",
  "epoch:17 -> loss:0.02593248523771763 , train_acc:0.8621333333333333,test_acc:0.8264",
  "epoch:18 -> loss:0.026287274435162544 , train_acc:0.8620833333333333,test_acc:0.8236",
  "epoch 19 saved! Because of TestAcc",
  "epoch:19 -> loss:0.025494147092103958 , train_acc:0.8619833333333333,test_acc:0.8384",
  "epoch:20 -> loss:0.026331504806876183 , train_acc:0.8630833333333333,test_acc:0.8213",
  "epoch:21 -> loss:0.02587689459323883 , train_acc:0.8617,test_acc:0.8258",
  "epoch:22 -> loss:0.025824708864092827 , train_acc:0.8621333333333333,test_acc:0.8256",
  "epoch:23 -> loss:0.02561669796705246 , train_acc:0.86135,test_acc:0.8186",
  "epoch:24 -> loss:0.026239411905407906 , train_acc:0.8632,test_acc:0.8171",
  "epoch:25 -> loss:0.026138750836253166 , train_acc:0.86155,test_acc:0.8199",
  "epoch:26 -> loss:0.026341114193201065 , train_acc:0.86125,test_acc:0.8297",
  "epoch:27 -> loss:0.026603227481245995 , train_acc:0.8601333333333333,test_acc:0.8292",
  "epoch:28 -> loss:0.0262700617313385 , train_acc:0.863,test_acc:0.8252",
  "epoch:29 -> loss:0.026804549619555473 , train_acc:0.8616333333333334,test_acc:0.8286",
  "epoch:30 -> loss:0.02596266008913517 , train_acc:0.8644666666666667,test_acc:0.8339",
  "epoch:31 -> loss:0.025962458923459053 , train_acc:0.8611833333333333,test_acc:0.8349",
  "epoch:32 -> loss:0.026533285155892372 , train_acc:0.8609833333333333,test_acc:0.8211",
  "epoch:33 -> loss:0.026329072192311287 , train_acc:0.8634333333333334,test_acc:0.8118",
  "epoch:34 -> loss:0.026944896206259727 , train_acc:0.8607,test_acc:0.8339",
  "epoch:35 -> loss:0.027136141434311867 , train_acc:0.8611833333333333,test_acc:0.8244",
  "epoch:36 -> loss:0.02684239111840725 , train_acc:0.8577666666666667,test_acc:0.828",
  "epoch:37 -> loss:0.026232918724417686 , train_acc:0.8602333333333333,test_acc:0.8342",
  "epoch:38 -> loss:0.027657954022288322 , train_acc:0.8608833333333333,test_acc:0.8146",
  "epoch:39 -> loss:0.026708079501986504 , train_acc:0.8589666666666667,test_acc:0.8263",
  "epoch:40 -> loss:0.027538979426026344 , train_acc:0.8608833333333333,test_acc:0.8322",
  "epoch:41 -> loss:0.026898302137851715 , train_acc:0.8591833333333333,test_acc:0.8217",
  "epoch:42 -> loss:0.028058422729372978 , train_acc:0.8595166666666667,test_acc:0.8235",
  "epoch:43 -> loss:0.02750696986913681 , train_acc:0.8569166666666667,test_acc:0.822",
  "epoch:44 -> loss:0.02726571448147297 , train_acc:0.8585333333333334,test_acc:0.827",
  "epoch:45 -> loss:0.026809701696038246 , train_acc:0.86115,test_acc:0.8337",
  "epoch:46 -> loss:0.02737932838499546 , train_acc:0.8593333333333333,test_acc:0.8225",
  "epoch:47 -> loss:0.027631213888525963 , train_acc:0.8592166666666666,test_acc:0.8192",
  "epoch:48 -> loss:0.027545854449272156 , train_acc:0.8596,test_acc:0.8303",
  "epoch:49 -> loss:0.02685708925127983 , train_acc:0.8604,test_acc:0.8125",
  "epoch:50 -> loss:0.02813146822154522 , train_acc:0.85775,test_acc:0.8168",
  "The Best Loss:0.02440614439547062!\nThe Best Train Accuracy:0.8647!\nThe Best Test Accuract:0.8384!"
]